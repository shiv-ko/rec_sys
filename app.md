あなたは Recommender System と Python 実装に詳しいソフトウェアエンジニア兼研究者です。  
以下の要件を満たす「MovieLens 100K を使った協調フィルタリングの実装＋実験＋レポート用アウトプット」をまとめてください。

# 全体ゴール

大学の推薦システムの授業の課題として、
MovieLens 100K データセットを用いて

1. Baseline：アイテム平均モデル
2. User-based Collaborative Filtering
3. Item-based Collaborative Filtering

を実装し、**同じデータ・同じ評価指標で性能比較を行う**。  
良い成績が取れるように、単なるコードだけでなく、

- 実験設計が妥当であること
- 授業内容とつながる理論的説明があること
- 結果の解釈と考察が書かれていること

も重視してください。

---

# 実装・実験に関する要件

## 1. データセット

- 対象：MovieLens 100K（ml-100k）
- 使用ファイル：`u.data`
  - カラム：`user_id, item_id, rating, timestamp`
- Python で扱いやすいように、実装では 0 始まりの `user_idx, item_idx` に変換してください。

要求するもの：
- 上記処理を行うコード
- どのように ID をエンコードしているかのコメント

## 2. Train/Test 分割

- 分割方法：**ユーザごとの leave-one-out**
  - 各ユーザについて `timestamp` でソートし、**最後の1件をテスト、残りをトレイン**とする。
- すべての手法（Baseline, User-based, Item-based）で **同じ train/test を共有**する。

要求するもの：
- この分割を行う関数
- なぜこの分割が「推薦タスクらしい」かの簡単な説明（未来の1件を予測するイメージ）

## 3. 行列の構築（Interaction Matrix）

- Train データから `num_users × num_items` の行列 `R_train` を作成
  - 観測された評価 → `rating` 値
  - 未観測 → 0

要求するもの：
- 上記行列を作る関数
- 「0 は未観測を表しており、本当の 0 評価ではない」ことをコードコメントで明示

---

## 4. Baseline：アイテム平均モデル

### モデル仕様
- 各アイテムについて、Train データ上の平均評価を計算する。
- 予測値：そのユーザ・アイテムの組 `(u, i)` に対して  
  → **アイテム i の平均評価**を返す。
- もしアイテム i に評価が一件もない場合は、グローバル平均（全評価の平均）を返す。

要求するもの：
- `ItemMeanBaseline` のようなクラス
  - `fit(train_df, num_items)`
  - `predict_single(user_idx, item_idx)`
- Baseline を使う意義の説明（「CF モデルが本当に賢いのかを判断するための比較対象」など）

---

## 5. User-based Collaborative Filtering

### 5-1. ユーザ平均と中心化

- 各ユーザ u について、評価しているアイテムの平均 `μ_u` を計算。
- 行列 `R` を「ユーザ平均で中心化」した `R_centered` を作成：
  - 評価がある要素だけ `rating - μ_u` とする。
- 授業で強調されていたように、「楽観的ユーザ／悲観的ユーザのバイアスを取り除くため」の処理であることをコメントで説明する。

### 5-2. 類似度計算（User-User）

- 中心化された `R_centered` を使って、**コサイン類似度**によりユーザ間類似度行列 `user_sim` を計算。
- 対角成分（自分自身との類似度）は 0 に設定。

### 5-3. 予測式（Top-k ユーザ）

- ユーザ u がアイテム i を評価していないとき、
  1. アイテム i を評価しているユーザ集合を抽出
  2. その中でユーザ u に似ているユーザを類似度順にソート
  3. 上位 k ユーザを近傍とし、以下の式で予測値を計算：

\[
\hat{r}_{ui} = \mu_u + 
\frac{\sum_{v \in N_k(u, i)} \text{sim}(u, v) \cdot (r_{vi} - \mu_v)}
{\sum_{v \in N_k(u, i)} |\text{sim}(u, v)|}
\]

- 近傍が見つからない場合は `μ_u` を返すなどのフォールバックを入れる。

要求するもの：
- `UserBasedCF` クラス
  - `fit(R_train)`：ユーザ平均計算、中心化、類似度行列の前計算
  - `predict_single(u, i)`：上記式に基づく予測
- ハイパーパラメータ `k` を引数として指定できるようにする。
- 類似度がすべて 0 や負になってしまう場合のガード処理も入れる。

---

## 6. Item-based Collaborative Filtering

### 6-1. Adjusted Cosine 類似度

- ユーザの評価バイアスを消すため、**ユーザ平均で中心化した行列**を用いてアイテム間類似度を計算する（Adjusted Cosine）。
- `R_centered` を転置して、`item × user` 形式にしてからコサイン類似度を計算し、`item_sim` 行列を得る。

### 6-2. 予測式（Top-k アイテム）

- ユーザ u がアイテム i を評価していないとき、
  1. ユーザ u が過去に評価したアイテム集合を取得
  2. その中でアイテム i に類似した上位 k アイテムを選ぶ
  3. それらの評価の類似度重み付き平均を予測値とする：

\[
\hat{r}_{ui} = 
\frac{\sum_{j \in N_k(i; u)} \text{sim}(i, j) \cdot r_{uj}}
{\sum_{j \in N_k(i; u)} |\text{sim}(i, j)|}
\]

- もしユーザ u が何も評価していない場合は、ユーザ平均やグローバル平均で代用する。

要求するもの：
- `ItemBasedCF` クラス
  - `fit(R_train)`：中心化＋アイテム類似度計算
  - `predict_single(u, i)`：上記式に基づく予測
- 「なぜ Item-based では同一ユーザ内での平均中心化が不要」という説明（スライドのポイント）もコメントで軽く触れる。

---

## 7. 評価指標と比較

### 7-1. レーティング予測（メイン）

- 指標：**RMSE** と **MAE**
- Test データの各 `(u, i, r_ui)` について
  - Baseline / User-based / Item-based それぞれで予測値を計算
  - 同じテストセット上で 3 手法を比較

### 7-2. Top-K 推薦（余裕があれば）

- 任意だが、できれば
  - leave-one-out のテストアイテムを「Top-K リストに入れられるか」で HitRate@K を計算する関数も実装
- 比較対象：
  - Baseline, User-based, Item-based それぞれの HitRate@10 など

要求するもの：
- `rmse`, `mae` を計算する共通関数
- （任意）HitRate@K を計算する関数
- 3 手法の結果を見やすい **表**（例：`pandas.DataFrame`）にまとめるコード

---

## 8. 実験設計とレポート向け要素

良い成績を取るため、以下を必ず含めてください。

### 8-1. ハイパーパラメータの検証

- 少なくとも User-based / Item-based の `k` について
  - 例：k = 5, 10, 20, 40 などで RMSE / MAE がどう変化するか
- 結果を表または簡単なグラフ（テキストベースでもよい）で示す。

### 8-2. 結果の比較と考察のための文章

次のポイントを盛り込んだ**日本語の解説テキスト**を生成してください。

- Baseline と比べて CF 手法がどの程度改善しているか
  - RMSE / MAE の具体的な数値差
  - その差が「意味のある差」と言えるかどうか
- User-based と Item-based の性能の違い
  - MovieLens 100K のようなデータでどちらが有利になりやすいか
  - データの疎密（ユーザ数 > アイテム数 or その逆）との関係
- 授業資料で説明されていたポイントとの対応づけ
  - mean-centering の効果
  - Top-k 近傍を取る意味
  - hit/miss の例を、推薦の直感と絡めて説明する

可能なら、以下も含めてください。
- この実装の限界（例：cold start 問題、計算コスト、すべての未観測を 0 と扱う問題など）
- もし Matrix Factorization や LLM などの高度な手法を使うならどう発展させられるか、簡単な展望

### 8-3. レポート構成案（アウトライン）

次のような構成案を日本語で出力してください（箇条書きでよい）。

1. 研究目的・課題の説明  
2. データセットの概要  
3. Baseline / User-based / Item-based のアルゴリズム説明  
4. 実装詳細（重要な式と処理の流れ）  
5. 実験設定（Train/Test 分割、ハイパーパラメータなど）  
6. 実験結果（表・図）  
7. 考察（性能比較・授業内容との関連・限界・今後の展望）  
8. まとめ  

---

## 9. コードスタイル・ドキュメントの要件

- すべての主要なクラス・関数に **docstring とコメント**をつける。
- 変数名は意味が分かるようにする（`R`, `user_sim` などは OK だがコメントで意味を明示）。
- ひとつの `main` スクリプトから
  - データ読み込み
  - 3 手法の学習・予測
  - 評価
  - 結果表示
  まで一通り実行できるようにする。

---


